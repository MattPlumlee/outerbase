[{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"covariance-functions","dir":"Articles","previous_headings":"","what":"Covariance functions","title":"Base walkthrough","text":"Covariance functions important building block Gaussian process inference. package, flexible classes. See ?covf information base class. Creating instances done ?methods::new call class name listed inside. cov method builds covariances matrices. covariance first columns first 5 elements ploted. Note designed single demensional covariance functions. Hyperparameters important almost covariance functions. control general shape predictive surface. stored covf class (editable) field hyp. can see effect alternating hyp correlation function.","code":"corf = new(covf_mat25) ?covf_mat25 xred = x[1:5,1] print(corf$cov(xred,xred),3) #>       [,1]  [,2]  [,3]  [,4]  [,5] #> [1,] 1.000 1.000 0.999 0.998 0.997 #> [2,] 1.000 1.000 1.000 0.999 0.998 #> [3,] 0.999 1.000 1.000 1.000 0.999 #> [4,] 0.998 0.999 1.000 1.000 1.000 #> [5,] 0.997 0.998 0.999 1.000 1.000 corf$hyp #>      [,1] #> [1,]    0 corf$hyp = c(-0.5) plot(x[,1],corf$cov(x[,1],0.5), type='l',      ylab='correlation with 0.5', xlab='input') corf$hyp = c(-0.25) lines(x[,1],corf$cov(x[,1],0.5), type='l') corf$hyp = c(0) lines(x[,1],corf$cov(x[,1],0.5), type='l')"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"gaussian-processes","dir":"Articles","previous_headings":"","what":"Gaussian processes","title":"Base walkthrough","text":"Gaussian processes long shown top performers near interpolation. information general Gaussian processes, see textbooks Gaussian Processes Machine Learning Surrogates, among others. idea represent surface realization Gaussian process controlled covariance function. outer product covariance functions can job three dimensions. means need first build correlation functions. multiply calculate covariances. goal predict number points, say 1000 points. built predictor (assuming y zero mean) using typical formulas. gives prediction accuracy can summarized .  can also use framework get predictive variances. equations explained documentation brevity. One point pretty well! plot looks standard Normal enough.","code":"corf1 = new(covf_mat25) corf2 = new(covf_mat25) corf3 = new(covf_mat25) corf1$hyp = c(-0.5) # just setting them all to the same  corf2$hyp = c(-0.5) # hyperparameter for now corf3$hyp = c(-0.5) covftot = function(x1,x2){   corf1$cov(x1[,1],x2[,1])*   corf2$cov(x1[,2],x2[,2])*   corf3$cov(x1[,3],x2[,3]) } cormattot = covftot(x,x) #total correlation matrix testsampsize = 1000 xtest = matrix(runif(testsampsize*d),ncol=d) yhat = covftot(xtest,x) %*% solve(cormattot,y) par(mfrow=c(1,2)) ytest = obtest_borehole3d(xtest) plot(yhat, ytest, ylab=\"actual\", xlab=\"prediction\")  hist(ytest-yhat, main=\"test residuals\",      xlab = \"test residuals\") sigma2hat = as.double(t(y)%*% solve(cormattot,y)/length(y))  varpred = sigma2hat*(covftot(xtest,xtest)-t(covftot(x,xtest))%*%   solve(cormattot,covftot(x,xtest))) hist((ytest-yhat)/sqrt(diag(varpred)),      main=\"standarized test residuals\",      xlab = \"standarized test residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"outermod-and-outerbase","dir":"Articles","previous_headings":"","what":"outermod and outerbase","title":"Base walkthrough","text":"core classes package ?outermod ?outerbase. outermod instance contains information build outerbase instance, build objects corresponding specific x. outerbase instance used build inference specific x.","code":""},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"outermod","dir":"Articles","previous_headings":"outermod and outerbase","what":"outermod","title":"Base walkthrough","text":"outermod instance created using new command. first step set covariances knots. set vector covfs, use ?setcovfs alongside vector strings covariances package. list can found listcov(). fixes dimension outermod instance om 3. need give set knot points dimension. choice still researched, choosing points spread dimension look like actual responses currently recommended. need invert matrix size knot points, recommended keep small, <50 general. function ?setknot used. can get set hyperparameters align general Gaussian processes inference.","code":"om = new(outermod) setcovfs(om, rep(\"mat25\",3)) knotlist = list(seq(0,1,by=0.025),                 seq(0,1,by=0.025),                 seq(0,1,by=0.025)) setknot(om, knotlist) gethyp(om) #> inpt1.scale inpt2.scale inpt3.scale  #>           0           0           0 om$updatehyp(c(-0.5,-0.5,-0.5)) gethyp(om) #> inpt1.scale inpt2.scale inpt3.scale  #>        -0.5        -0.5        -0.5"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"outerbase","dir":"Articles","previous_headings":"outermod and outerbase","what":"outerbase","title":"Base walkthrough","text":"outerbase equivalent basis matrix fast computation methods included. basically just builds set basis functions dimension, sometimes just look like polynomials. quite polynomials, covfs give different shapes. call outermod$getbase allow access basis functions dimension.","code":"ob = new(outerbase,           om, #give it the outermod (reference)           x) #give it the input matrix basis_func = ob$getbase(1) matplot(x[,1],basis_func[,1:4],          type='l', ylab=\"func\", xlab=\"first dim\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"outermod-and-outerbase-1","dir":"Articles","previous_headings":"outermod and outerbase","what":"outermod and outerbase","title":"Base walkthrough","text":"outermod outerbase meant used conjunction . One key ingredient outermod$selecterms function, allows pick products basis functions best represent current outermod response. outermod$getvar tell us vector variances associated coefficients terms. specific basis matrix can formed getting basis matrix selected terms.","code":"p = 60 terms = om$selectterms(p) # 60 by 3 matrix head(terms) #>      [,1] [,2] [,3] #> [1,]    0    0    0 #> [2,]    0    0    1 #> [3,]    1    0    0 #> [4,]    0    1    0 #> [5,]    1    1    0 #> [6,]    1    0    1 covcoeff = as.vector(om$getvar(terms)) basismat = ob$getmat(terms)  termno = 5 basevec = ob$getbase(1)[,terms[termno,1]+1]*   ob$getbase(2)[,terms[termno,2]+1]*   ob$getbase(3)[,terms[termno,3]+1]  cbind(basevec[1:5],basismat[1:5,5]) #equal #>             [,1]        [,2] #> [1,]  1.04581481  1.04581481 #> [2,]  0.48401755  0.48401755 #> [3,]  1.26856977  1.26856977 #> [4,] -0.24727429 -0.24727429 #> [5,] -0.08951811 -0.08951811"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"feature-space-approximation","dir":"Articles","previous_headings":"","what":"Feature space approximation","title":"Base walkthrough","text":"package leverages insight Gaussian processes linear combinations basis functions random coefficients. viewpoint often called feature space view Gaussian processes. understand valuable, first show take covcoeff basismat together, correlation function well approximated following manipulation. means can leverage Bayesian linear regression prediction. require assuming noisevar, also called nugget Gaussian process literature.","code":"cormatob = basismat %*% diag(covcoeff ) %*% t(basismat)  print(round(cormattot[1:5,1:5],3)) # typical gp #>       [,1]  [,2]  [,3]  [,4]  [,5] #> [1,] 1.000 0.985 0.531 0.545 0.802 #> [2,] 0.985 1.000 0.537 0.597 0.860 #> [3,] 0.531 0.537 1.000 0.875 0.729 #> [4,] 0.545 0.597 0.875 1.000 0.857 #> [5,] 0.802 0.860 0.729 0.857 1.000 print(round(cormatob[1:5,1:5],3)) # outerbase #>       [,1]  [,2]  [,3]  [,4]  [,5] #> [1,] 1.000 0.985 0.530 0.545 0.802 #> [2,] 0.985 1.000 0.537 0.597 0.860 #> [3,] 0.530 0.537 0.999 0.875 0.729 #> [4,] 0.545 0.597 0.875 1.000 0.857 #> [5,] 0.802 0.860 0.729 0.857 1.000 noisevar = 10^(-4) #posterior precision matrix of coefficients postcov = solve(1/noisevar*t(basismat)%*%basismat+                    1/sigma2hat*diag(1/covcoeff)) #posterior mean of coefficients coeffest = postcov%*%(1/noisevar*t(basismat)%*%y)"},{"path":"https://mattplumlee.github.io/outerbase/articles/basebasics.html","id":"predictions-and-comparison","dir":"Articles","previous_headings":"","what":"Predictions and comparison","title":"Base walkthrough","text":"Consider predicting new xtest examine inference works traditional Gaussian process feature space approximation. predictions nearly equivalent.  histograms residuals show similar matching.  standardized residuals, account variance, also show similar matching.","code":"obtest = new(outerbase,           om, #same outermod            xtest) #give it the input matrix  basistest = obtest$getmat(terms) yhatob = basistest%*%coeffest par(mfrow=c(1,2)) plot(yhat, ytest, main=\"typical gp\",      xlab=\"prediction\", ylab=\"actual\") plot(yhatob, ytest, main = \"outerbase equiv.\",      xlab=\"prediction\", ylab=\"actual\") par(mfrow=c(1,2)) hist(ytest-yhat, main=\"typical gp\",      xlab=\"test residuals\") hist(ytest-yhatob, main=\"outerbase equiv.\",      xlab=\"test residuals\") varpredob = basistest%*%postcov%*%t(basistest)  par(mfrow=c(1,2)) hist((ytest-yhat)/sqrt(diag(varpred)), main=\"typical gp\",      xlab=\"standarized test residuals\") hist((ytest-yhatob)/sqrt(diag(varpredob)), main=\"outerbase equiv.\",      xlab=\"standarized test residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/gettingstarted.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting started","text":"goal outerbase make production near-interpolators easy, stable, scalable. based C++ backend, powered specifically Rcpp. Specifically, leverages unique, fast linear algebra using RcppArmadillo (Armadillo) omp. overall structure designed interacted object-oriented manner using Rcpp modules. ways interact outerbase uncomfortable (just actively detest) object oriented programming. begin, load package. Note built package source, make sure use compiler can process omp commands access entire speed benefits.","code":"library(outerbase)"},{"path":"https://mattplumlee.github.io/outerbase/articles/gettingstarted.html","id":"simple-prediction","dir":"Articles","previous_headings":"","what":"Simple prediction","title":"Getting started","text":"understand get started using package, try predict using data function eight dimensional input commonly known Borehole function. First generate 1000 points using test function built package ?obtest_borehole8d. goal design predictor y given x near-interpolator. simplest way interact package using ?obfit (fitting outerbase). function requires x, y two objects. value numb number basis functions want use. choice numb still research, generally want large-ish. Play around! underlying concepts approach come Gaussian processes. Thus core building block predictors covariances functions. choice covariances needed obfit list strings corresponding columns x. Type listcov() discover covariance functions currently deployed. curious , type, e.g. ?covf_mat25pow. Note obfit checks place prevent serious damage. foolproof. one correct deployment, mat25pow used dimensions. can predict using obpred. Consider predicting training points, can see interpolator, close.  fact generated data means can show outerbase can reasonably predict ground truth, meaning overfitting issue.  1000 test points generated way original data can also serve verification process. predictions get also outstanding new points. quite good residuals test set, extrapolating .  package also produces variances predictions can use test reasonableness. fact second histogram looks like standard Normal promising predictions reasonable.","code":"sampsize = 400 d = 8 x = matrix(runif(sampsize*d),ncol=d) #uniform samples y = obtest_borehole8d(x) + 0.5*rnorm(sampsize) listcov() #> [1] \"mat25pow\" \"mat25\"    \"mat25ang\" obmodel = obfit(x, y, covnames=rep(\"elephant\",8)) #> Error in .checkcov(covnames[k], x[, k]):  #>  covariances must be from listcov() obmodel = obfit(x, y[1:200], covnames=rep(\"mat25pow\",5)) #> Error in obfit(x, y[1:200], covnames = rep(\"mat25pow\", 5)):  #>  x and y dims do not align obmodel = obfit(x[1:2,], y[1:2], covnames=rep(\"mat25pow\",8)) #> Error in obfit(x[1:2, ], y[1:2], covnames = rep(\"mat25pow\", 8)):  #>  dimension larger than sample size has not been tested obmodel = obfit(x, y, numb = 2, covnames=rep(\"mat25pow\",8)) #> Error in obfit(x, y, numb = 2, covnames = rep(\"mat25pow\", 8)):  #>  number of basis functions should be over twice the dimension obmodel = obfit(100*x, y, covnames=rep(\"mat25pow\",8)) #> Error in .checkcov(covnames[k], x[, k]):  #>  x ranges exceed limits of covariance functions  #>  the limits are between 0 and 1   #>  try rescaling obmodel = obfit(0.001*x, y, covnames=rep(\"mat25pow\",8)) #> Error in .checkcov(covnames[k], x[, k]):  #>  x are too small for ranges #>  the limits are between 0 and 1   #>  try rescaling obmodel = obfit(x, y, numb = 300, covnames=rep(\"mat25pow\",8)) predtr = obpred(obmodel, x) rmsetr = sqrt(mean((y-predtr$mean)^2)) plot(predtr$mean, y,      main=paste(\"training \\n RMSE = \", round(rmsetr,3)),      xlab=\"prediction\", ylab = \"actual\") ytrue = obtest_borehole8d(x) rmsetr = sqrt(mean((ytrue-predtr$mean)^2)) plot(predtr$mean, ytrue,      main=paste(\"oracle \\n RMSE = \", round(rmsetr,3)),      xlab=\"prediction\", ylab=\"actual\") xtest = matrix(runif(1000*d),ncol=d) #prediction points ytest = obtest_borehole8d(xtest) + 0.5*rnorm(1000) predtest = obpred(obmodel, xtest)  rmsetst = sqrt(mean((ytest-predtest$mean)^2)) plot(predtest$mean, ytest,       main=paste(\"testing \\n RMSE = \", round(rmsetst,3)),      xlab=\"prediction\", ylab=\"actual\") hist((ytest-predtest$mean),      main=\"testing \\n  residuals\", xlab=\"residuals\") hist((ytest-predtest$mean)/sqrt(predtest$var),      main=\"testing \\n standarized residuals\",      xlab=\"standarized residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/learning.html","id":"hyperparameter-impact","dir":"Articles","previous_headings":"","what":"Hyperparameter impact","title":"Learning from data","text":"values hyperparameters extremely important successful near-interpolation surfaces. impact felt outerbase section designed illustrate . Let’s take look projected basis functions.  hyperparameters now changed way know change basis functions. Note ob$build required updating hyperparameters take effect. leads asymmetric basis function set first dimension power transform ?covf_mat25pow.","code":"sampsize = 100 design1d = seq(1/(2*sampsize),1-1/(2*sampsize),1/sampsize) x = cbind(design1d,sample(design1d),sample(design1d)) ob = new(outerbase, om, x) basis_func0 = ob$getbase(1) matplot(x[,1],basis_func0[,1:4],          type='l', ylab=\"func\", xlab=\"first dim\") hyp0 = gethyp(om) hyp0[2] = 3 #changing the power on first parameter om$updatehyp(hyp0) ob$build() #rebuild after updatehyp basis_func1 = ob$getbase(1) par(mfrow=c(1,2)) matplot(x[,1],basis_func0[,1:4],          type='l', ylab=\"func\", xlab=\"first dim\",         main=\"original hyperparameters\") matplot(x[,1],basis_func1[,1:4],          type='l', ylab=\"func\", xlab=\"first dim\",         main=\"new hyperparameters\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/learning.html","id":"lpdf-for-learning","dir":"Articles","previous_headings":"","what":"lpdf for learning","title":"Learning from data","text":"core building block outerbase learning base class ?lpdf, log probability density functions. base class forms backbone behind many possible statistical models. Instances class allow us optimize coefficients, infer uncertainty learn hyperparmeters covariance functions. small dataset can illustrate (almost) core concepts related lpdf. can reset hyperparameters , 2 dimensions covariance function total 6 hyperparameters. use 60 terms build approximation. idea build loglik object represent log likelihood data given model coefficients. begin ?loglik_std, although model recommended speed reasons. can initialize check can get gradients respect coefficients, covariance hyperparameters, parameters lpdf object . reasonable predictor also needs prior coefficients. tells us distribution expect coefficients. make handling two objects loglik logpr easier, ?lpdfvec class helpful tie object together. share hyperparameter vector , need based outermod object. concatenate parameters. coefficients coeff considered ancillary parameters need optimized (something sophisticated, hint current research). class, easiest via lpdf$optnewton, takes single Newton step optimize coefficients. test data help illustrate prediction. can see predictive accuracy using ?predictor class automatically pulls correct information loglik design predictions.","code":"sampsize = 30 d = 3 design1d = seq(1/(2*sampsize),1-1/(2*sampsize),1/sampsize) x = cbind(design1d,sample(design1d),sample(design1d)) y = obtest_borehole3d(x) hyp0 = c(-0.5,0,-0.5,0,-0.5,0) om$updatehyp(hyp0) hyp0 = gethyp(om) p = 60 terms = om$selectterms(p) loglik = new(loglik_std, om, terms, y, x)  coeffhere = rep(0,loglik$nterms) loglik$update(coeffhere) # update it to get gradients loglik$val #> [1] -167.617 head(loglik$grad) # dim 60 for number of coeffients #>            [,1] #> [1,] -0.1142062 #> [2,] -0.7362125 #> [3,] -0.4712837 #> [4,]  3.5520678 #> [5,]  0.2677359 #> [6,] -0.5759347 logpr = new(logpr_gauss, om, terms) logpdf = new(lpdfvec, loglik, logpr) para0 = getpara(logpdf) para0[2] = 4 logpdf$updatepara(para0) getpara(logpdf) #> noisescale coeffscale  #>   2.883507   4.000000 logpdf$optnewton() testsampsize = 1000 xtest = matrix(runif(testsampsize*d),ncol=d) ytest = obtest_borehole3d(xtest) predt = new(predictor,loglik) predt$update(xtest) yhat = as.vector(predt$mean()) varpred = as.vector(predt$var())  par(mfrow=c(1,2)) plot(yhat,ytest, xlab=\"prediction\", ylab=\"actual\") hist((ytest-yhat)/sqrt(varpred),      main=\"standarized test residuals\",      xlab = \"standarized test residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/learning.html","id":"lpdf-and-hyperparameters","dir":"Articles","previous_headings":"","what":"lpdf and hyperparameters","title":"Learning from data","text":"main value approach automated pulling important gradients related covariance hyperparameters model parameters. allows us use custom functions learn hyperparameters give maximum predictive power. goal right now single point estimate hyperparameters. One careful keep good ranges, call make sure return -inf problem chosen hyperparameters. works pulling right information checking make sure objects thing parameters reasonable. package provides custom deployment BFGS ?BFGS_std optimize functions like . just update parameters re-optimize. steps can nicely wrapped another function ?BFGS_lpdf, simpler call result. Note things fully understood, numbers match exactly , quite close functionally . revised predictions built hyperparameter optimization find improved predictive accuracy nearly every category.","code":"logpdf$optnewton() logpdf$gradhyp    # dim 6 for all hyperparameter #>            [,1] #> [1,] -0.5379479 #> [2,]  0.2656740 #> [3,]  9.1485696 #> [4,]  0.9366525 #> [5,]  8.8462368 #> [6,]  0.8878728 logpdf$gradpara   # dim 2 since 2 parameters #>            [,1] #> [1,] -17.314951 #> [2,]  -3.696204 totobj = function(hypl) { #my optimization function for tuning   regpara = logpdf$paralpdf(hypl$para) # get regularization for lpdf   reghyp = om$hyplpdf(hypl$hyp) # get regularization for om   if(is.finite(regpara) && is.finite(reghyp)) { # if they pass     om$updatehyp(hypl$hyp)        # update hyperparameters     logpdf$updateom()             # update the outerbase inside     logpdf$updatepara(hypl$para)  # update parameter     logpdf$optnewton()            # do opt          gval = hypl #match structure     gval$hyp = -logpdf$gradhyp-om$hyplpdf_grad(hypl$hyp)     gval$para = -logpdf$gradpara-logpdf$paralpdf_grad(hypl$para)     list(val = -logpdf$val-reghyp-regpara, gval = gval)   } else list(val = Inf, gval = hypl) } hypl = list(para = getpara(logpdf), hyp = gethyp(om)) totobj(hypl) #> $val #> [1] 83.1685 #>  #> $gval #> $gval$para #>           [,1] #> [1,] 17.314951 #> [2,]  3.196204 #>  #> $gval$hyp #>             [,1] #> [1,]  -4.8191949 #> [2,]  -0.2656740 #> [3,] -14.5057125 #> [4,]  -0.9366525 #> [5,] -14.2033796 #> [6,]  -0.8878728 opth = BFGS_std(totobj, hypl, verbose=3) # #> [1] \"doing opt...\" #> [1] \"Wolfe conditions\" #> [1]  -3.108195 -45.489967 #> [1] 80.05974 #> [1] \"Wolfe conditions\" #> [1] -1.1202703  0.7819948 #> [1] 75.77655 #> [1] \"Wolfe conditions\" #> [1] -14.34444 -19.93960 #> [1] 61.43021 #> [1] \"Wolfe conditions\" #> [1] -5.327744 -4.157325 #> [1] 56.1018 #> [1] \"Wolfe conditions\" #> [1] -6.808514 -3.315549 #> [1] 49.29249 #> [1] \"Wolfe conditions\" #> [1] -9.311435 -8.292266 #> [1] 39.97985 #> [1] \"Wolfe conditions\" #> [1] -5.732378 -3.352411 #> [1] 34.24677 #> [1] \"Wolfe conditions\" #> [1] -5.021418 -6.928486 #> [1] 29.22464 #> [1] \"Wolfe conditions\" #> [1] -0.6595542 -5.5666767 #> [1] 28.56484 #> [1] \"Wolfe conditions\" #> [1] -0.4196691 -0.5877661 #> [1] 28.14511 #> [1] \"Wolfe conditions\" #> [1] -0.04979228 -0.05796315 #> [1] \"finished opt...\" om$updatehyp(opth$vec$hyp) logpdf$updatepara(opth$vec$para) logpdf$optnewton() opth = BFGS_lpdf(om, logpdf,                   rho=hypl,                   verbose = 3, newt= T)   #> [1] \"doing opt...\" #> [1] \"Wolfe conditions\" #> [1]  -3.108195 -45.489967 #> [1] 80.05974 #> [1] \"Wolfe conditions\" #> [1] -1.1202703  0.7819948 #> [1] 75.77655 #> [1] \"Wolfe conditions\" #> [1] -14.34444 -19.93960 #> [1] 61.43021 #> [1] \"Wolfe conditions\" #> [1] -5.327744 -4.157325 #> [1] 56.1018 #> [1] \"Wolfe conditions\" #> [1] -6.808514 -3.315549 #> [1] 49.29249 #> [1] \"Wolfe conditions\" #> [1] -9.311435 -8.292266 #> [1] 39.97985 #> [1] \"Wolfe conditions\" #> [1] -5.732378 -3.352411 #> [1] 34.24677 #> [1] \"Wolfe conditions\" #> [1] -5.021418 -6.928486 #> [1] 29.22464 #> [1] \"Wolfe conditions\" #> [1] -0.6595542 -5.5666767 #> [1] 28.56484 #> [1] \"Wolfe conditions\" #> [1] -0.4196691 -0.5877661 #> [1] 28.14511 #> [1] \"Wolfe conditions\" #> [1] -0.04979228 -0.05796315 #> [1] \"finished opt...\" predtt = new(predictor,loglik) predtt$update(xtest) yhat = as.vector(predtt$mean()) varpred = as.vector(predtt$var())  par(mfrow=c(1,2)) plot(ytest,yhat) hist((ytest-yhat)/sqrt(varpred), main=\"standarized test residuals\",      xlab = \"standarized test residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/articles/speed.html","id":"different-models","dir":"Articles","previous_headings":"","what":"Different models","title":"Speeding up inference","text":"begin, lets use ?loglik_std represent slow approach. logpdf_slow can optimized using lpdf$optnewton. Newton’s method involves solving linear system, thus takes one step, expensive. ?loglik_gauss lpdf model designed speed. nice comparison loglik_gauss uses model loglik_std, approximations speed. logpdf_fast error try use optnewton. written never builds hess matrix. suggested use lpdf$optcg (conjugate gradient) optimize coefficients fast version. aside, omp speed ups possible, need correctly compiled omp. One check call following. answer 1 multi-threaded processor (modern processors), things likely mis-aligned. can manually set number threads lpdf objects.","code":"loglik_slow = new(loglik_std, om, terms, y, x)  logpr_slow = new(logpr_gauss, om, terms) logpdf_slow = new(lpdfvec, loglik_slow, logpr_slow) logpdf_slow$optnewton() loglik_fast = new(loglik_gauss, om, terms, y, x)  logpr_fast = new(logpr_gauss, om, terms) logpdf_fast = new(lpdfvec, loglik_fast, logpr_fast) logpdf_fast$optnewton() #> Error in logpdf_fast$optnewton(): addition: incompatible matrix dimensions: 0x0 and 250x250 logpdf_fast$optcg(0.001, 100) ob = new(outerbase, om, x)  ob$nthreads #> [1] 2 logpdf_slow$setnthreads(4) logpdf_fast$setnthreads(4)"},{"path":"https://mattplumlee.github.io/outerbase/articles/speed.html","id":"timing","dir":"Articles","previous_headings":"","what":"Timing","title":"Speeding up inference","text":"main cost models like hyperparameter optimization. Thus show difference time build hyperparameters. Let’s save starting points (since share om) fairness. Test points verify predictions equally good either model, difference speed. use unsophisticated proc.time quick timing comparisons.","code":"hyp0_slow = list(para = getpara(logpdf_slow), hyp = gethyp(om)) hyp0_fast = list(para = getpara(logpdf_fast), hyp = gethyp(om)) xtest = matrix(runif(1000*d),ncol=d) #prediction points ytest =  obtest_borehole8d(xtest) ptm = proc.time() opth = BFGS_lpdf(om, logpdf_slow,                   rho=hyp0_slow, newt=T)   t_slow = proc.time() - ptm pred_slow = new(predictor,loglik_slow) pred_slow$update(xtest) yhat_slow = as.vector(pred_slow$mean()) print(t_slow) #>    user  system elapsed  #>  18.466   0.012  17.782 ptm = proc.time() opth = BFGS_lpdf(om, logpdf_fast,                   rho=hyp0_fast, newt=F)   t_fast = proc.time() - ptm pred_fast = new(predictor,loglik_fast) pred_fast$update(xtest) yhat_fast = as.vector(pred_fast$mean()) print(t_fast) #>    user  system elapsed  #>   1.996   0.068   1.304"},{"path":"https://mattplumlee.github.io/outerbase/articles/speed.html","id":"comparison-of-results","dir":"Articles","previous_headings":"","what":"Comparison of results","title":"Speeding up inference","text":"simply plotting results tells story: faster inference discernible dropoff quality.","code":"par(mfrow=c(1,2)) rmse_slow = sqrt(mean((ytest-yhat_slow)^2)) hist((ytest-yhat_slow), main=paste(\"slow method \\n rmse:\",                                      round(rmse_slow,3),                                    \", time:\",                                    round(t_slow[3],2),'s'),      xlab = \"prediction residuals\") rmse_fast = sqrt(mean((ytest-yhat_fast)^2)) hist((ytest-yhat_fast), main=paste(\"fast method \\n rmse =\",                                       round(rmse_fast,3),                                    \", time:\",                                    round(t_fast[3],2),'s'),       xlab = \"prediction residuals\")"},{"path":"https://mattplumlee.github.io/outerbase/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Matthew Plumlee. Author, maintainer.","code":""},{"path":"https://mattplumlee.github.io/outerbase/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Plumlee M (2022). outerbase: Outer product bases precise estimation prediction. https://mattplumlee.github.io/outerbase, https://github.com/MattPlumlee/outerbase.","code":"@Manual{,   title = {outerbase: Outer product bases for precise estimation and prediction},   author = {Matthew Plumlee},   year = {2022},   note = {https://mattplumlee.github.io/outerbase, https://github.com/MattPlumlee/outerbase}, }"},{"path":"https://mattplumlee.github.io/outerbase/index.html","id":"outerbase","dir":"","previous_headings":"","what":"Outer product bases for precise estimation and prediction","title":"Outer product bases for precise estimation and prediction","text":"outerbase package creates high-dimensional approximations (near-interpolaters) using outer product basis function structure. can used construct predictors high-dimensional inputs stable consistent remains accurate massive data leverages large parallel computing resources accommodates flexible data generation CRAN package way, Github reliable way check project: predictors can rendered flexible accuracy depending available resources.","code":"# Install development version from GitHub devtools::install_github(\"mattplumlee/outerbase\")"},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_lpdf.html","id":null,"dir":"Reference","previous_headings":"","what":"BFGS lpdf — BFGS_lpdf","title":"BFGS lpdf — BFGS_lpdf","text":"wrapper codeBFGS_std useful easily calling  parameter optimization package lines possible. Note om logpdf set optimal  parameters, return simply information.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_lpdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BFGS lpdf — BFGS_lpdf","text":"","code":"BFGS_lpdf(om, logpdf, rho = list(), newt = F, ...)"},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_lpdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BFGS lpdf — BFGS_lpdf","text":"om outermod object logpdf lpdf object rho initial point, initialized objects needed newt bool Newtons method used ... additional parameters passed BFGS_std","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_lpdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BFGS lpdf — BFGS_lpdf","text":"list information optimization","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_std.html","id":null,"dir":"Reference","previous_headings":"","what":"BFGS standard — BFGS_std","title":"BFGS standard — BFGS_std","text":"generic minimization function funcw takes list rho using Broyden-Fletcher-Goldfarb-Shanno algorithm. Useful hyperparameter optimization handles infs  fairly easily.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_std.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BFGS standard — BFGS_std","text":"","code":"BFGS_std(funcw, rho, ..., verbose = 0)"},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_std.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BFGS standard — BFGS_std","text":"funcw object optimize rho initial point ... additional parameters passed funcw verbose Integer 0-3 larger prints information","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/BFGS_std.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BFGS standard — BFGS_std","text":"list information optimization","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/covf.html","id":null,"dir":"Reference","previous_headings":"","what":"covariance function class — covf","title":"covariance function class — covf","text":"base class designed handle specific features  covariances needed outerbase.  Polymorphism allows implied  methods used across several similar classes.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/covf.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"covariance function class — covf","text":"covf$hyp hyperparameters specific correlation function covf$lowbnd,covf$uppbnd upper lower bounds inputs  covariance function. covf$cov(x1,x2) returns covariance matrix two vectors  inputs x1 x2 covf$covdiag(x1) returns diagonal covariance matrix  x1 covf$cov_gradhyp(x1,x2) returns cube gradient cov  respect covariance hyperparameters","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/covf_mat25.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern covariance function — covf_mat25","title":"Matern covariance function — covf_mat25","text":"standard Matern covariance function form $$c(x_1,x_2) = (1+ |h| + h^2/3) \\exp(-|h|) $$ \\(h = (x_1-x_2)/\\rho\\) \\(\\rho\\)=exp(2*hyp[0]).","code":"covf = new(covf_mat25)"},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/covf_mat25ang.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern covariance function with angular transform — covf_mat25ang","title":"Matern covariance function with angular transform — covf_mat25ang","text":"standard Matern covariance function power transformation form $$c(x_1,x_2) = (1+ |h| + h^2/3) \\exp(-|h|) $$ $$h = (\\sin(x_1)-\\sin(x_2))^2/\\rho_s +  (\\cos(x_1)-\\cos(x_2))^2/\\rho_c,.$$ hyp two dimensional vector  \\(\\rho_s\\)=exp(2*hyp[0]) \\(\\rho_c\\)=exp(2*hyp[1]).","code":"covf = new(covf_mat25ang)"},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/covf_mat25pow.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern covariance function with power transform — covf_mat25pow","title":"Matern covariance function with power transform — covf_mat25pow","text":"standard Matern covariance function power transformation form $$c(x_1,x_2) = (1+ |h| + h^2/3) \\exp(-|h|) $$ \\(h = (x_1^\\alpha-x_2^\\alpha)/\\rho\\) hyp two  dimensional vector \\(\\rho\\)=exp(2*hyp[0]+0.25*hyp[1]) \\(\\alpha\\)=exp(2*hyp[0]).","code":"covf = new(covf_mat25pow)"},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/gethyp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the hyperparameters — gethyp","title":"Get the hyperparameters — gethyp","text":"function gets current hyperparameters outermod object.  formats way makes reading `R` helpful.","code":"hyp = gethyp(om)"},{"path":"https://mattplumlee.github.io/outerbase/reference/gethyp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the hyperparameters — gethyp","text":"om outermod object","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/gethyp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the hyperparameters — gethyp","text":"","code":"om = new(outermod) setcovfs(om, c(\"mat25\", \"mat25\", \"mat25\")) hyp = gethyp(om) print(hyp) #> inpt1.scale inpt2.scale inpt3.scale  #>           0           0           0"},{"path":"https://mattplumlee.github.io/outerbase/reference/getpara.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the model parameters — getpara","title":"Get the model parameters — getpara","text":"function gets current parameters lpdf object.   formats way makes reading `R` helpful.","code":"para = getpara(loglik)"},{"path":"https://mattplumlee.github.io/outerbase/reference/getpara.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the model parameters — getpara","text":"lpdf logpdf object","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/listcov.html","id":null,"dir":"Reference","previous_headings":"","what":"list all covariance functions — listcov","title":"list all covariance functions — listcov","text":"list covariance functions","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/listcov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list all covariance functions — listcov","text":"","code":"listcov()"},{"path":"https://mattplumlee.github.io/outerbase/reference/listcov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"list all covariance functions — listcov","text":"list names covariance functions recommend edition.  first default.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_gauss.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian errors, large scale — loglik_gauss","title":"Gaussian errors, large scale — loglik_gauss","text":"standard model form $$y = \\langle \\phi(x), \\theta \\rangle + \\varepsilon, \\varepsilon \\sim  N(0,\\sigma^2)$$ \\(\\phi(x)\\) basis, \\(\\theta\\) coefficient vector, \\(\\varepsilon\\) unseen noise vector.  parameter vector length 1  para \\(= \\log(\\sigma)\\).  slightly (sometimes) version loglik_std  allows can handle diagonal variational  inference.","code":"loglik = new(loglik_gauss, om, terms, y, x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_gauss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian errors, large scale — loglik_gauss","text":"om outermod object referred terms matrix terms, must many columns dims  om y vector observations x matrix predictors, must many columns dims  om number rows y","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_gda.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian errors with diagonal adjustment — loglik_gda","title":"Gaussian errors with diagonal adjustment — loglik_gda","text":"standard model form $$y = \\langle \\phi(x), \\theta \\rangle + \\delta(x) + \\varepsilon, \\delta(x) \\sim N(0, \\lambda g(x)), \\varepsilon \\sim N(0,\\sigma^2)$$ \\(\\phi(x)\\) basis, \\(\\theta\\) coefficient vector, \\(\\delta(x)\\) unseen vector corresponding unmodeled  variance \\(\\lambda g(x)\\), \\(\\varepsilon\\) unseen noise vector. parameter vector length 2  \\(\\sigma=\\) exp(para[0]) \\(\\lambda=\\)exp(2 para[1]).","code":"loglik = new(loglik_gda, om, terms, y, x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_gda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian errors with diagonal adjustment — loglik_gda","text":"om outermod object referred terms matrix terms, must many columns dims  om y vector observations x matrix predictors, must many columns dims  om number rows y","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_std.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian errors — loglik_std","title":"Gaussian errors — loglik_std","text":"standard model form $$y = \\langle \\phi(x), \\theta \\rangle + \\varepsilon, \\varepsilon \\sim  N(0,\\sigma^2)$$ \\(\\phi(x)\\) basis, \\(\\theta\\) coefficient vector, \\(\\varepsilon\\) unseen noise vector. parameter vector length 1  para \\(= \\log(\\sigma)\\).  slightly slower (sometimes)  version loglik_gauss allows complete marginal  inference.","code":"loglik = new(loglik_std, om, terms, y, x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/loglik_std.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian errors — loglik_std","text":"om outermod object referred terms matrix terms, must many columns dims  om y vector observations x matrix predictors, must many columns dims  om number rows y","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/logpr_gauss.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian prior — logpr_gauss","title":"Gaussian prior — logpr_gauss","text":"standard model coefficents drawn independently $$ \\theta_i \\sim N(0, \\rho c_i)$$ \\(c_i\\) variance supplied om $$th term.  parameter vector length 1  \\(\\rho=\\) exp(para[0]).","code":"logpr = new(logpr_gauss, om, terms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/logpr_gauss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian prior — logpr_gauss","text":"om outermod object referred terms matrix terms, must many columns dims  om","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdf-cash-optcg.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimization via Conjugate Gradient — lpdf$optcg","title":"Optimization via Conjugate Gradient — lpdf$optcg","text":"optimizes coefficient vector coeff using conjugate gradient.  currently designed quadratic lpdf objects.","code":"lpdf$optcg(tol,epoch)"},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdf-cash-optcg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimization via Conjugate Gradient — lpdf$optcg","text":"tol positive double representing tolerance, default  0.001. epoch positive integer representing maximum number steps  conjugate gradient take.","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdf-cash-optnewton.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimization via Newton's Method — lpdf$optnewton","title":"Optimization via Newton's Method — lpdf$optnewton","text":"optimizes coefficient vector coeff using Newton's Method.   currently designed quadratic lpdf objects.   take single step.","code":"lpdf$optnewton()"},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Log probability density function class — lpdf","title":"Log probability density function class — lpdf","text":"base class designed handle learning  underlying coefficients, hyperparameters, parameters associated specific learning instance.  Polymorphism allows implied methods  used across several similar classes.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdf.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Log probability density function class — lpdf","text":"lpdf$val current value lpdf$para current model parameters lpdf$coeff current coefficients lpdf$compute_val calling update, compute value store  val lpdf$grad current gradient respect coefficients lpdf$gradhyp current gradient respect covariance hyperparameters lpdf$gradpara current gradient respect model parameters lpdf$compute_grad calling update, compute gradient  respect coefficients store grad lpdf$compute_gradhyp calling update, compute gradient respect covariance hyparameters store gradhyp lpdf$compute_gradpara calling update, compute gradient respect model parameters store gradpara lpdf$update(coeff) update using new coefficients lpdf$optcg(tol,epoch) optimization respect coefficients  via conjugate gradient lpdf$optnewton() optimization via matrix inversion, one Newton  step lpdf$updateom() update based recent version outermod lpdf$updatepara(para) update using new model parameters lpdf$updateterms(terms) update using new terms lpdf$hess() returns hessian respect  coefficients lpdf$hessgradhyp() returns gradient hess() respect  covariance hyperparameters lpdf$hessgradpara() returns gradient hess() respect  model parameters lpdf$diaghess() returns diagonal hessian  respect coefficients lpdf$diaghessgradhyp() returns gradient diaghess() ","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdfvec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector of lpdf objects — lpdfvec","title":"Vector of lpdf objects — lpdfvec","text":"class contains two lpdf object can  manipulated single object.  presumes based outermod object, thus share hyperparameters.  However model parameters concatenated.  Currently also includes variations marginal adjustments. Currently designed pair, ordering arbitrary.","code":"logpdf = new(lpdfvec, loglik, logpr)"},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdfvec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector of lpdf objects — lpdfvec","text":"loglik one reference lpdf object logpr another reference lpdf object shares  outermod  loglik","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/lpdfvec.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Vector of lpdf objects — lpdfvec","text":"lpdfvec$domarg boolean controls marginal adjustment  done","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/obfit.html","id":null,"dir":"Reference","previous_headings":"","what":"fit an outerbase — obfit","title":"fit an outerbase — obfit","text":"fit outerbase","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fit an outerbase — obfit","text":"","code":"obfit(x, y, numb = 100, covnames = NULL)"},{"path":"https://mattplumlee.github.io/outerbase/reference/obfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fit an outerbase — obfit","text":"x n d sized matrix inputs y n length vector outputs numb size basis use covnames d length vector covariance names","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fit an outerbase — obfit","text":"Saving important model information","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obpred.html","id":null,"dir":"Reference","previous_headings":"","what":"pred from an outerbase — obpred","title":"pred from an outerbase — obpred","text":"pred outerbase","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obpred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pred from an outerbase — obpred","text":"","code":"obpred(obmodel, x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/obpred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pred from an outerbase — obpred","text":"obmodel output obfit x new m d sized matrix inputs","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obpred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pred from an outerbase — obpred","text":"list mean var new x","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Three dim borehole example — obtest_borehole3d","title":"Three dim borehole example — obtest_borehole3d","text":"three dimensional Borehole function used illustrations.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Three dim borehole example — obtest_borehole3d","text":"","code":"obtest_borehole3d(x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Three dim borehole example — obtest_borehole3d","text":"x n 3 vector inputs","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Three dim borehole example — obtest_borehole3d","text":"length n vector outputs","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole8d.html","id":null,"dir":"Reference","previous_headings":"","what":"Eight dim borehole example — obtest_borehole8d","title":"Eight dim borehole example — obtest_borehole8d","text":"eight dimensional Borehole function used illustrations.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole8d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eight dim borehole example — obtest_borehole8d","text":"","code":"obtest_borehole8d(x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole8d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eight dim borehole example — obtest_borehole8d","text":"x n 8 vector inputs","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/obtest_borehole8d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eight dim borehole example — obtest_borehole8d","text":"length n vector outputs","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-build.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds the outerbase — outerbase$build","title":"Builds the outerbase — outerbase$build","text":"Build (re-build) basis based recent evaluation  outermod.","code":"outerbase$build()"},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getbase.html","id":null,"dir":"Reference","previous_headings":"","what":"Get base functions — outerbase$getbase","title":"Get base functions — outerbase$getbase","text":"Returns basis dimension","code":"basis_func = outerbase$getbase(k)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getbase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get base functions — outerbase$getbase","text":"k integer corresponds dimension.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getbase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get base functions — outerbase$getbase","text":"basis_func matrix evaluated basis functions  dimension.  Designed mostly visualization.","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getmat.html","id":null,"dir":"Reference","previous_headings":"","what":"Get basis matrix — outerbase$getmat","title":"Get basis matrix — outerbase$getmat","text":"Returns basis matrix","code":"basismat = outerbase$getmat(terms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get basis matrix — outerbase$getmat","text":"terms matrix terms","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-getmat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get basis matrix — outerbase$getmat","text":"basismat matrix evaluated basis functions based  terms.","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix multiply — outerbase$matmul","title":"Matrix multiply — outerbase$matmul","text":"Multiplies basis times vector without building basis  matrix.","code":"b = outerbase$matmul(terms, a)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix multiply — outerbase$matmul","text":"terms matrix terms vector length rows terms","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix multiply — outerbase$matmul","text":"b vector resulting matrix multiplication","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-tmatmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose Matrix multiply — outerbase$tmatmul","title":"Transpose Matrix multiply — outerbase$tmatmul","text":"Multiplies transpose basis times vector without   building basis matrix.","code":"b = outerbase$tmatmul(terms, a)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-tmatmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose Matrix multiply — outerbase$tmatmul","text":"terms matrix terms vector length rows outerbase","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-cash-tmatmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose Matrix multiply — outerbase$tmatmul","text":"b vector resulting matrix multiplication","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-package.html","id":null,"dir":"Reference","previous_headings":"","what":"outerbase — outerbase-package","title":"outerbase — outerbase-package","text":"High-dimensional function approximation using outer product models. Research methods currently investigation, published resource posted available. Early testing shown promising results.","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"outerbase — outerbase-package","text":"Maintainer: Matthew Plumlee mplumlee@northwestern.edu","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase.html","id":null,"dir":"Reference","previous_headings":"","what":"Outer product-type basis — outerbase","title":"Outer product-type basis — outerbase","text":"Object handles basis given set points  x.","code":"ob = new(outerbase, om, x)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outer product-type basis — outerbase","text":"x matrix predictors, must many columns dims  om","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Outer product-type basis — outerbase","text":"nthreads number threads omp use outerbase$getbase(k) get dimensions basis  functions outerbase$getmat(terms) get basis matrix  terms outerbase$build() (re)build basis object outerbase$matmul(terms,) matrix multiply without  building basis matrix outerbase$tmatmul(terms,) transpose matrix multiply  without building basis matrix","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outerbase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outer product-type basis — outerbase","text":"","code":"om = new(outermod) setcovfs(om, c(\"mat25\", \"mat25\", \"mat25\")) setknot(om,          list(seq(0,1,by=0.025),seq(0,1,by=0.025),seq(0,1,by=0.025))) x = matrix(runif(10*3),ncol=3) ob = new(outerbase, om, x) terms = om$selectterms(40) basismat = ob$getmat(terms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-getvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Get variance of coefficients — outermod$getvar","title":"Get variance of coefficients — outermod$getvar","text":"Returns variance coefficients associated terms.","code":"coeffvar = outermod$getvar(terms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-getvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get variance of coefficients — outermod$getvar","text":"terms matrix terms","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-getvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get variance of coefficients — outermod$getvar","text":"coeffvar vector variances coefficient","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-selectterms.html","id":null,"dir":"Reference","previous_headings":"","what":"Select optimal terms — outermod$selectterms","title":"Select optimal terms — outermod$selectterms","text":"Selects best terms given current outermod","code":"terms = om$selectterms(numterms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-selectterms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select optimal terms — outermod$selectterms","text":"numterms Number basis terms desired","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-selectterms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select optimal terms — outermod$selectterms","text":"terms matrix terms","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-updatehyp.html","id":null,"dir":"Reference","previous_headings":"","what":"Update hyperparameters — outermod$updatehyp","title":"Update hyperparameters — outermod$updatehyp","text":"Updates hyperparameters","code":"outermod$updatehyp(hyp)"},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod-cash-updatehyp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update hyperparameters — outermod$updatehyp","text":"hyp vector hyperparameters","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod.html","id":null,"dir":"Reference","previous_headings":"","what":"Outer product-type model — outermod","title":"Outer product-type model — outermod","text":"Type name class see methods.","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Outer product-type model — outermod","text":"setcovfs set covariance functions setknot set knot points gethyp get hyperparameters outermod$updatehyp update hyperparameters outermod$selectterms find best terms outermod$getvar find variances coefficients","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/outermod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outer product-type model — outermod","text":"","code":"om = new(outermod) setcovfs(om, c(\"mat25\", \"mat25\", \"mat25\")) setknot(om,          list(seq(0,1,by=0.01),seq(0,1,by=0.01),seq(0,1,by=0.01))) terms = om$selectterms(40) coeffvar =om$getvar(terms) hyp = gethyp(om) hyp[1:2] = 0.5 om$updatehyp(hyp) coeffvar = om$getvar(terms)"},{"path":"https://mattplumlee.github.io/outerbase/reference/predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"prediction class — predictor","title":"prediction class — predictor","text":"base class design allow coherent building predictions across multiple models.  Unlike many base classes  package, meant directly used.","code":"pred = new(predictor, logpdf)"},{"path":"https://mattplumlee.github.io/outerbase/reference/predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"prediction class — predictor","text":"logpdf lpdf instance build predictor","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/predictor.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"prediction class — predictor","text":"predictor$update(x) update current input prediction predictor$mean() return current mean prediction predictor$var() return current var prediction","code":""},{"path":"https://mattplumlee.github.io/outerbase/reference/setcovfs.html","id":null,"dir":"Reference","previous_headings":"","what":"Set covariance functions — setcovfs","title":"Set covariance functions — setcovfs","text":"function sets covariance functions outermod object, first thing one creating outermod object.//'","code":"setcovfs(om, covnames)"},{"path":"https://mattplumlee.github.io/outerbase/reference/setcovfs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set covariance functions — setcovfs","text":"om outermod object covnames vector strings covariance functions","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/setcovfs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set covariance functions — setcovfs","text":"","code":"om = new(outermod) setcovfs(om, c(\"mat25\", \"mat25\", \"mat25\")) setcovfs(om, c(\"mat25\", \"mat25pow\", \"mat25\", \"mat25ang\"))"},{"path":"https://mattplumlee.github.io/outerbase/reference/setknot.html","id":null,"dir":"Reference","previous_headings":"","what":"Set knot points — setknot","title":"Set knot points — setknot","text":"function sets knot points estimate eigenfunctions eigenvalues. naturally check knot points dimension covariance functions.  also check  knot points within reasonable bounds covariance functions.//'","code":"setknot(om, knotslist)"},{"path":"https://mattplumlee.github.io/outerbase/reference/setknot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set knot points — setknot","text":"om outermod object knotslist list one dimensional vectors","code":""},{"path":[]},{"path":"https://mattplumlee.github.io/outerbase/reference/setknot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set knot points — setknot","text":"","code":"om = new(outermod) setcovfs(om, c(\"mat25\", \"mat25\", \"mat25\")) setknot(om,          list(seq(0,1,by=0.01),seq(0,1,by=0.01),seq(0,1,by=0.01)))"},{"path":"https://mattplumlee.github.io/outerbase/news/index.html","id":"outerbase-010","dir":"Changelog","previous_headings":"","what":"outerbase 0.1.0","title":"outerbase 0.1.0","text":"Initial release! Contains base functionality.","code":""}]
